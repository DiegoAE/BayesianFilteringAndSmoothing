{
 "metadata": {
  "name": "",
  "signature": "sha256:fdd6ef9445c824a17668707d15e74a87c3892d525e6b263403c887e74a95a520"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 1(TODO)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Assume that we have obtained $T$ measurement pairs $(x_k,y_k)$ from the linear regression model\n",
      "\n",
      "\\begin{align}\n",
      "\ty_k = \\theta_1 x_k + \\theta_2, \\qquad k = 1, 2, \\cdots, T.\n",
      "\\end{align}\n",
      "\n",
      "The purpose is now to derive estimates of the parameters $\\theta_1$ and $\\theta_2$ such that the following error is minimized (least squares estimate):\n",
      "\n",
      "\\begin{align}\n",
      "\tE(\\theta_1,\\theta_2) = \\sum_{k=1}^{T} \\begin{pmatrix} y_k - \\theta_1 x_k - \\theta_2 \\end{pmatrix}^2.\n",
      "\\end{align}\n",
      "\n",
      "1. Define $\\mathbf{y} = \\begin{bmatrix}y_1 & \\cdots & y_T\\end{bmatrix}^\\top$ and $\\mathbf{\\theta} = \\begin{bmatrix}\\theta_1 & \\theta_2\\end{bmatrix}^\\top$. Show that the set of Equations of the regression model can be written in matrix form as $\\mathbf{y} = \\mathbf{X} \\mathbf{\\theta}$ with a suitably defined matrix $\\mathbf{X}$.\n",
      "2. Write the least squares error function in matrix form in terms of $\\mathbf{y}$, $\\mathbf{X}$ and $\\mathbf{\\theta}$.\n",
      "3. Compute the gradient of the matrix form error function and solve the least squares estimate of the parameter $\\mathbf{\\theta}$ by finding the point where the gradient is zero."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Solution Exercise 1."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "if $\\mathbf{X}$ is defined as follows\n",
      "\n",
      "$$\n",
      "\\mathbf{X} = \\begin{bmatrix}\n",
      "    x_1 & 1 \\\\ \n",
      "    x_2 & 1 \\\\ \n",
      "    \\vdots & \\vdots \\\\\n",
      "    x_k & 1 \\\\\n",
      "    \\vdots & \\vdots \\\\\n",
      "    x_T & 1 \\\\\n",
      "\\end{bmatrix}\n",
      "$$\n",
      "\n",
      "Then the regression model can written as:\n",
      "\n",
      "$$\n",
      "\\begin{bmatrix}\n",
      "    y_1 \\\\ \n",
      "    y_2 \\\\ \n",
      "    \\vdots \\\\\n",
      "    y_k \\\\\n",
      "    \\vdots \\\\\n",
      "    y_T \\\\\n",
      "\\end{bmatrix}\n",
      " = \n",
      "\\begin{bmatrix}\n",
      "    x_1 & 1 \\\\ \n",
      "    x_2 & 1 \\\\ \n",
      "    \\vdots & \\vdots \\\\\n",
      "    x_k & 1 \\\\\n",
      "    \\vdots & \\vdots \\\\\n",
      "    x_T & 1 \\\\\n",
      "\\end{bmatrix}\n",
      "\\begin{bmatrix}\n",
      "    \\theta_1  \\\\\n",
      "    \\theta_2\n",
      "\\end{bmatrix}\n",
      "$$\n",
      "\n",
      "Or equivalently:\n",
      "\n",
      "$$ \\mathbf{y} = \\mathbf{X} \\mathbf{\\theta} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The error function can be written in terms of $y$, $\\mathbf{X}$ and $\\mathbf{\\theta}$ as:\n",
      "\n",
      "$$ E(\\mathbf{\\theta}) = (\\mathbf{y} - \\mathbf{X} \\mathbf{\\theta})^\\top (\\mathbf{y} - \\mathbf{X} \\mathbf{\\theta}) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Expanding the form of error function we have:\n",
      "    \n",
      "$$ \n",
      "\\begin{align}\n",
      "E(\\mathbf{\\theta}) & = \\mathcal{y}^\\top \\mathcal{y} - \\mathcal{y}^\\top \\mathbf{X} \\mathbf{\\theta} - (\\mathbf{X} \\mathbf{\\theta})^\\top y + (\\mathbf{X} \\mathbf{\\theta})^\\top \\mathbf{X} \\mathbf{\\theta} \\\\ \n",
      "                   & = \\mathcal{y}^\\top \\mathcal{y} - 2 \\mathcal{y}^\\top \\mathbf{X} \\mathbf{\\theta}  + \\mathbf{\\theta}^\\top \\mathbf{X}^\\top \\mathbf{X} \\mathbf{\\theta}\n",
      "\\end{align}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Taking the derivative of $E(\\mathbf{\\theta})$ with respect to $\\mathbf{\\theta}$ we have"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "$$\n",
      " \\frac{\\partial E}{\\partial \\mathbf{\\theta}} = -2 \\mathbf{X} y + 2 \\mathbf{X}^\\top \\mathbf{X} \\mathbf{\\theta}\n",
      "$$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By equating to $0$ the gradient and rearranging:\n",
      "\n",
      "$$\n",
      " \\mathbf{X}^\\top \\mathbf{X} \\mathbf{\\theta} = \\mathbf{X} y \n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Therefore the least squares estimate of $\\mathbf{\\theta}$ is given by:\n",
      "\n",
      "$$ \\mathbf{\\theta} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X} y $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 3."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Download and install the EKF/UKF toolbox to some Matlab computer from the web page: \n",
      "\n",
      "    ```\n",
      "            http://becs.aalto.fi/en/research/bayes/ekfukf/\n",
      "    ```\n",
      "\n",
      "    Run the following demonstrations:\n",
      "\n",
      "    ```\n",
      "            demos/kf_sine_demo/kf_sine_demo.m\n",
      "            demos/kf_cwpa_demo/kf_cwpa_demo.m\n",
      "    ```\n",
      "\n",
      "    After running them, read the contents of these files and try to understand how they have been implemented. Also read the documentations of functions ```kf_predict``` and ```kf_update``` (type e.g. ```help kf_predict``` in Matlab).\n",
      "    \n",
      "2. Consider the following state space model:\n",
      "\n",
      "    $$\\begin{align}\n",
      "            \\mathbf{x_k} &= \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\mathbf{x_{k-1}} + \\mathbf{w_{k-1}} \\\\\n",
      "            \\mathbf{y_k}  &= \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\mathbf{x_{k-1}} + v_{k}\t\t\n",
      "    \\end{align}$$\n",
      "\n",
      "    where $x_k = \\begin{bmatrix}x_k & \\dot{x}_k \\end{bmatrix}^\\top$ is the state, $y_k$ is the measurement, and $\\mathbf{w_k} \\sim \\mathcal{N}(\\mathbf{0}, \\text{diag}(\\frac{1}{10^2}, 1))$ and $v_k \\sim \\mathcal{N}(0, 10^2)$ are white Gaussian noise processes.\n",
      "\n",
      "    Simulate a 100 step state sequence from the model and plot the signal $x_k$, signal derivative $\\dot{x}_k$ and the simulated measurements $y_k$. Start from an initial state drawn from a zero-mean 2d-Gaussian distribution with identity covariance.\n",
      "    \n",
      "3. Use the Kalman filter for computing the state estimates $\\mathbf{m_k}$ using the following kind of Matlab-code:\n",
      "    \n",
      "    ```\n",
      "    m = [0;0]; % Initial mean\n",
      "    P = eye(2); % Initial covariance\n",
      "    for k = 1:100\n",
      "        [m,P] = kf_predict(m,P,A,Q);\n",
      "        [m,P] = kf_update(m,P,y(k),H,R);\n",
      "        % Store the estimate m of state x_k here\n",
      "    end\n",
      "    ```\n",
      " \n",
      "4. Plot the state estimates $\\mathbf{m_k}$, the true states $\\mathbf{x_k}$ and measurements $y_k$. Compute the RMSE (root mean square error) of using the first components of vectors $\\mathbf{m_k}$ as the estimates of first components of states $\\mathbf{x_k}$. Also compute the RMSE error that we would have if we used the measurements as the estimates."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## TODO."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}