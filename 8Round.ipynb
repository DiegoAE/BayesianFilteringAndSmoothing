{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1. (EM for Gaussian random walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement the $EM$ algorithm for estimation of the measurement noise variance in the Gaussian random walk model. \n",
    "2. Simulate data with 256 time steps and test the algorithm. How many iterations are needed for convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercise 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the random walk can be written in state space form in the following way:\n",
    "\n",
    "$$\n",
    "x_k = x_{k - 1} + q  \\qquad q \\sim \\mathcal{N}(0, Q)\n",
    "$$\n",
    "$$\n",
    "y_k = x_{k} + r \\qquad r \\sim \\mathcal{N}(0, R)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to derive the $EM$ algorithm for the random walk we should write down the complete data log-likelihood for the model given a set of parameters $\\mathbf{\\theta}$ which is:\n",
    "\n",
    "$$\n",
    " \\log p(\\mathbf{y}_{1:T}, \\mathbf{x}_{0:T} | \\theta) = \\log(x_0|\\theta) + \\sum_{k=1}^T \\log p(x_k|x_{k-1}, \\theta) + \\sum_{k=1}^T \\log p(y_k | x_k,\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the $E$ step we define the function $Q(\\theta, \\theta^{(n)})$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Q(\\theta, \\theta^{(n)})& = E[\\log p(\\mathbf{y}_{1:k}, \\mathbf{x}_{0:k} | \\theta)] \\\\\n",
    "                       & = E[\\log(x_0|\\theta)] + \\sum_{k=1}^T E[ \\log p(x_k|x_{k-1}, \\theta) ] + \\sum_{k=1}^T E[\\log p(y_k | x_k,\\theta)]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the expectation $E[.]$ is defined in terms of $p(\\mathbf{x}_{0:T} | \\theta^{(n)}, \\mathbf{y}_{1:T})$. Formally,\n",
    "\n",
    "$$\n",
    "E[g(x)] = \\int g(\\mathbf{x}_{0:T}) p(\\mathbf{x}_{0:T} | \\theta^{(n)}, \\mathbf{y}_{1:T}) d\\mathbf{x}_{0:T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in this case the parameter we want to estimate is the measurement noise variance ($R$) and it only affects $ p(y_k | x_k)$. Then the function $Q(.,.)$ can be rewritten as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Q(R, R^{(n)})& =  \\sum_{k=1}^T E[\\log p(y_k | x_k, R)] + constant \\\\\n",
    "                       & = \\sum_{k=1}^T \\int \\log p(y_k | x_k, R) p(x_k | R^{(n)}, \\mathbf{y}_{1:T}) d{x}_{k} + constant\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to derive the $M$ step. In this step we have to optimize $Q(.,.)$ with respect to $R$. Expanding the last expression we get:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "Q(R, R^{(n)}) & = \\sum_{k=1}^T \\int \\bigg(-\\frac{1}{2}\\log 2\\pi - \\frac{1}{2}\\log R - \\frac{(y_k - x_k)^2}{2R}\\bigg) \\mathcal{N}(x_k | m_k^s, P_k^s) d{x}_{k} + constant \\\\\n",
    "              & = \\sum_{k=1}^T \\int \\bigg(-\\frac{1}{2}\\log 2\\pi - \\frac{1}{2}\\log R - \\frac{(y_k - x_k)^2}{2R}\\bigg) \\mathcal{N}(x_k | m_k^s, P_k^s) d{x}_{k} + constant \\\\\n",
    "              & = \\sum_{k=1}^T -E[\\frac{1}{2}\\log 2\\pi] - E[\\frac{1}{2}\\log R] - \\frac{E[y_k^2]}{2R} + \\frac{E[y_k x_k]}{2R} - \\frac{E[x_k^2]}{2R} + constant\\\\\n",
    "              & = \\sum_{k=1}^T - \\frac{1}{2}\\log R - \\frac{y_k^2}{2R} +  \\frac{2 y_k E[x_k]}{2R} - \\frac{E[x_k^2]}{2R} + constant \\\\\n",
    "              & = \\sum_{k=1}^T - \\frac{1}{2}\\log R - \\frac{y_k^2}{2R} +  \\frac{y_k m_k^s}{R} - \\frac{P_k^s + (m_k^s)^2 }{2R} + constant \\\\\n",
    "              & = \\sum_{k=1}^T - \\frac{1}{2}\\log R - \\frac{y_k^2}{2R} +  \\frac{y_k m_k^s}{R} - \\frac{P_k^s}{2R} - \\frac{(m_k^s)^2 }{2R} + constant\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the the expectation above $E[.]$ is defined in terms of the probability distribution $\\mathcal{N}(x_k | m_k^s, P_k^s)$ where $m_k^s$ and $P_k^s$ are the resulting mean and covariance from the $RTS$ smoother for state $x_k\n",
    "$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to maximize $Q(R, R^{(n)})$ with respect to $R$. Taking derivatives we have.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial Q(R, R^{(n)})}{\\partial R} & = \\frac{\\partial }{\\partial R} \\bigg( \\sum_{k=1}^T - \\frac{1}{2}\\log R - \\frac{y_k^2}{2R} +  \\frac{y_k m_k^s}{R} - \\frac{P_k^s}{2R} - \\frac{(m_k^s)^2 }{2R} \\bigg) \\\\\n",
    "                                          & = \\sum_{k=1}^T - \\frac{1}{2R} + \\frac{y_k^2}{2 R^2} -  \\frac{y_k m_k^s}{R^2} + \\frac{P_k^s}{2R^2} + \\frac{(m_k^s)^2 }{2R^2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to make the derivative equal to $0$ in order to maximize:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{k=1}^T - \\frac{1}{2R} + \\frac{y_k^2}{2 R^2} -  \\frac{y_k m_k^s}{R^2} + \\frac{P_k^s}{2R^2} + \\frac{(m_k^s)^2 }{2R^2}\n",
    "& = 0 \\\\\n",
    "\\sum_{k=1}^T - \\frac{R}{2} + \\frac{y_k^2}{2} - {y_k m_k^s} + \\frac{P_k^s}{2} + \\frac{(m_k^s)^2 }{2}\n",
    "& = 0 \\\\\n",
    " -\\frac{RT}{2} + \\sum_{k=1}^T  \\frac{y_k^2}{2} - {y_k m_k^s} + \\frac{P_k^s}{2} + \\frac{(m_k^s)^2 }{2}\n",
    "& = 0 \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last equality defines an update equation for $R$ using the output (i.e $m_k^s$, $P_k^s$) of the *RTS* smoother using the old value of $R$ (i.e. $R^{(n)}$). Namely,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "R = \\frac{1}{T} \\sum_{k=1}^T  {y_k^2} - 2{y_k m_k^s} + {P_k^s} + {(m_k^s)^2 }\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to iteratively estimate the value of $R$. The implementation is based on the EFK/UKF toolbox since the Kalman filtering and RTS smoothing were already implemented in previous rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script octave\n",
    "   \n",
    "%% Data Generation\n",
    "\n",
    "A = 1;\n",
    "H = 1;\n",
    "steps = 256;\n",
    "T = 1:steps;\n",
    "x = randn;\n",
    "\n",
    "Q = 0.1;\n",
    "R = 3.0;\n",
    "\n",
    "X = zeros(1, steps);\n",
    "Y = zeros(1, steps);\n",
    "for i = 1:steps\n",
    "    x = A * x + sqrt(Q) * randn;\n",
    "    y = H * x + sqrt(R) *randn;\n",
    "    X(i) = x;\n",
    "    Y(i) = y;\n",
    "end\n",
    "\n",
    "\n",
    "%% EM\n",
    "\n",
    "\n",
    "em_iteraciones = 100;\n",
    "\n",
    "R_est = 100; % initial estimation\n",
    "\n",
    "est = zeros(1, em_iteraciones);\n",
    "\n",
    "for i = 1:em_iteraciones\n",
    "\n",
    "    % Kalman Filtering with current parameter value\n",
    "    m0 = 0.0;\n",
    "    P0 = 1;\n",
    "    m = m0;\n",
    "    P = P0;\n",
    "    MM = zeros(size(m,1),size(Y,2));\n",
    "    PP = zeros(size(m,1),size(m,1),size(Y,2));\n",
    "    for k=1:size(Y,2)\n",
    "        [m,P] = kf_predict(m,P,A,Q);\n",
    "        [m,P] = kf_update(m,P,Y(:,k),H,R_est); % using the current estimate\n",
    "        MM(:,k) = m;\n",
    "        PP(:,:,k) = P;\n",
    "    end\n",
    "    % RTS Smoothing \n",
    "    [SM,SP] = rts_smooth(MM,PP,A,Q);\n",
    "    % Actual EM\n",
    "    new_R_est = sum(Y .* Y) - 2 * sum(Y .* SM) + sum(SP) + sum(SM .* SM);\n",
    "    new_R_est = new_R_est / size(Y, 2);\n",
    "    R_est = new_R_est;\n",
    "    est(i) = R_est;\n",
    "end\n",
    "\n",
    "time = 1:em_iteraciones;\n",
    "plot(time , est, time, R );\n",
    "legend('EM Estimation','Real Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAGACAIAAABUQk3oAAAACXBIWXMAAA3XAAAN1wFCKJt4AAAA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\nAABCCQBAKAEACCUAAKH+B5+/bbiHWwhRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='em_convergence_8_1.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Value | EM Estimate | Error\n",
    "--- | --- | ---\n",
    "3.0 | 2.9806 | 0.0194"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2. (Energy function approach)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement the algorithm for computing the energy function for the Gaussian random walk model as well as its derivative with respect to the noise variance (via the sensitivity equations in Appendix A.3 in Simos book).\n",
    "2. Generate some simulated data (you can use the same data in both Exercise 1 and 2) and use a gradient based optimization method (e.g. fminunc in Matlab) to find the ML estimate of the parameter.\n",
    "3. Plot the likelihood curve for values around the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercise 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The energy function for the given model depends on the unknown parameter $\\theta$ (i.e. measurement variance) and can be recursively computed using the following expression:\n",
    "\n",
    "$$\n",
    "    \\varphi_k(\\theta) = \\varphi_{k-1}(\\theta) + \\frac{1}{2} \\log | 2 \\pi S_k(\\theta)| + \\frac{v_k(\\theta)^2}{S_k(\\theta)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the terms $S_k(R)$ and $v_k(R)$  are given by the Kalman filter iteration over the whole measurements sequece fixing the measurement variance to $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative with respect to $R$ can also be recursively computed as follows (*Bayesian Filtering and Smoothing, Appendix A.3*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "    \\varphi^{'}_k(\\theta) = \\varphi^{'}_{k-1}(\\theta) + \\frac{S^{'}_k(\\theta)}{2S_k(\\theta)}  + \\frac{v_k(\\theta) v^{'}_k(\\theta)}{S_k(\\theta)} - \\frac{v^2_k(\\theta) S^{'}_k(\\theta)}{2S^2_k(\\theta)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "S^{'}_k(\\theta) &= P^{' -}_k(\\theta) + R^{'}(\\theta)\\\\\n",
    "v^{'}_k(\\theta) &= - m^{' -}_k(\\theta) \\\\\n",
    "m^{' -}_k(\\theta)&= m^{'}_{k-1}(\\theta) \\\\\n",
    "P^{' -}_k(\\theta) &= P^{'}_{k-1}(\\theta) \\\\ \n",
    "R^{'}(\\theta) &= 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above derivation it has been taken into account that $A'(\\theta) = H'(\\theta) = Q'(\\theta) = 0$ Since they don't depend on the measurement noise.\n",
    "\n",
    "We are left with the problem of computing $m^{'}_{k-1}(\\theta)$ and $P^{'}_{k-1}(\\theta)$ which can be done using the following update equation for $m^{'}_{k}(\\theta)$ and $P^{'}_{k}(\\theta)$  :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "m^{'}_{k}(\\theta) &= m^{' -}_{k}(\\theta) + K^{'}_k(\\theta) v_k(\\theta) + K_k(\\theta) v^{'}_k(\\theta)   \\\\\n",
    "P^{'}_{k}(\\theta) &= P^{' -}_{k}(\\theta) - 2 K^{'}_k(\\theta) S_k(\\theta) K_k(\\theta) - (K_k(\\theta))^2 S^{'}_k(\\theta)\\\\\n",
    "K^{'}_k(\\theta) &=   \\frac{P^{' -}_{k}(\\theta)}{S_k(\\theta)} - \\frac{P^{-}_{k}(\\theta) S^{'}_k(\\theta)}{S_k(\\theta)^2}\n",
    "\\end{align} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is implemented below. First of all the objective function and its corresponding gradients are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function [f, g] = objective_and_gradient(theta)\n",
    "\n",
    "    % Data Generation\n",
    "    \n",
    "    % Lock seed\n",
    "    randn('state',123);  % make sure the same data is generated each time  \n",
    "    A = 1;\n",
    "    H = 1;\n",
    "    steps =5000;\n",
    "    T = 1:steps;\n",
    "    x = randn;\n",
    "\n",
    "    Q = 0.1;\n",
    "    R = 3.0;\n",
    "\n",
    "    X = zeros(1, steps);\n",
    "    Y = zeros(1, steps);\n",
    "    for i = 1:steps\n",
    "        x = A * x + sqrt(Q) * randn;\n",
    "        y = H * x + sqrt(R) *randn;\n",
    "        X(i) = x;\n",
    "        Y(i) = y;\n",
    "    end\n",
    "    \n",
    "    % Do Kalman Filtering\n",
    "    \n",
    "    m2 = 0;  % Initialize first step\n",
    "    P2 = 1; % Some uncertanty in covariance\n",
    "    \n",
    "    % Store useful variables\n",
    "    SSk = zeros(1, steps);\n",
    "    vvk = zeros(1, steps);\n",
    "    KKk = zeros(1, steps);\n",
    "    Pk_pred = zeros(1, steps);\n",
    "\n",
    "    % Run Kalman filter\n",
    "    for k=1:steps\n",
    "      % Prediction step\n",
    "      m2 = A * m2;\n",
    "      P2 = A * P2 * A' + Q;\n",
    "      Pk_pred(k) = P2;\n",
    "      % Update step\n",
    "      vk = Y(k) - H * m2;\n",
    "      Sk = H * P2 * H' + theta; % using the current parameter\n",
    "      Kk = (P2 * H') / Sk;\n",
    "      m2 = m2 + Kk * vk;\n",
    "      P2 = P2 - Kk * Sk * Kk';\n",
    "      % Store the results\n",
    "      SSk(k) = Sk;\n",
    "      vvk(k) = vk;\n",
    "      KKk(k) = Kk;\n",
    "    end\n",
    "    \n",
    "    % A gaussian prior was assumed over theta\n",
    "    m_theta = 0;\n",
    "    P_theta = 1;\n",
    "    % initialization of energy function (-log P(theta))\n",
    "    f = 0.5 * log(2 * pi * P_theta) + (theta - m_theta)^2/(2*P_theta);\n",
    "    % initialization of the gradient of the energy function\n",
    "    % derivative wrt theta of -log P(theta)\n",
    "    g = (theta - m_theta) / P_theta;\n",
    "    % initial values for recursion\n",
    "    % they don't depend on theta so derivative is zero\n",
    "    mkp = 0; \n",
    "    Pkp = 0;\n",
    "    for k = 1:steps\n",
    "        % objective function recursion\n",
    "        f = f + 0.5 * log(abs(2*pi*SSk(k))) + 0.5*(vvk(k)^2)/SSk(k);\n",
    "        % gradient recursion\n",
    "        mkp_ = mkp;\n",
    "        Pkp_ = Pkp;\n",
    "        Skp = Pkp_ + 1;\n",
    "        vkp = -mkp_ ;\n",
    "        g = g + Skp/(2*SSk(k)) + (vvk(k)*vkp)/SSk(k) ...\n",
    "            - 0.5 * ((vvk(k)^2) * Skp)/(SSk(k)^2);\n",
    "        % Computing the current values necessary for next iteration\n",
    "        KKp = Pkp_/SSk(k) - (Pk_pred(k) * Skp) / (SSk(k)^2);\n",
    "        mkp = mkp_ + KKp * vvk(k) + KKk(k) * vkp;\n",
    "        Pkp = Pkp_ - 2 * KKp * SSk(k) * KKk(k) - KKk(k) * KKk(k) * Skp; \n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a gradient-based optimization algorithm is executed with an initial guess of the unknown parameter (i.e measurement variance noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script octave\n",
    "%% Estimation via Energy function\n",
    "\n",
    "theta = 100.; % initial guess\n",
    "options = optimoptions(@fminunc, 'GradObj','on');\n",
    "[x,f,flag,output] = fminunc(@objective_and_gradient,theta, options);\n",
    "\n",
    "\n",
    "%% Plotting the likelihood function\n",
    "\n",
    "delta = 0.1; \n",
    "right = x + delta * (0:30);\n",
    "left = x - delta * fliplr(1:20);\n",
    "search_space = [left, right]\n",
    "\n",
    "Y = zeros(1, size(search_space,2));\n",
    "for i = 1:size(search_space,2)\n",
    "    Y(i) = -objective_and_gradient(search_space(i));\n",
    "end\n",
    "\n",
    "plot(search_space, Y);\n",
    "title('log-likelihood of theta values')\n",
    "xlabel('\\theta')\n",
    "ylabel('log-likelihodd');\n",
    "saveas(gcf,'R8_log_likelihood_8_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAGACAIAAABUQk3oAAAACXBIWXMAAA3XAAAN1wFCKJt4AAAA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\nevQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='R8_log_likelihood_8_2.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Value | Energy function Estimate | Error\n",
    "--- | --- | ---\n",
    "3.0 | 2.8660 | 0.1340"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
