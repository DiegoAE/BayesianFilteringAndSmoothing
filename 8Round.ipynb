{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1. (EM for Gaussian random walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement the $EM$ algorithm for estimation of the measurement noise variance in the Gaussian random walk model. \n",
    "2. Simulate data with 256 time steps and test the algorithm. How many iterations are needed for convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercise 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the random walk can be written in state space form in the following way:\n",
    "\n",
    "$$\n",
    "x_k = x_{k - 1} + q  \\qquad q \\sim \\mathcal{N}(0, Q)\n",
    "$$\n",
    "$$\n",
    "y_k = x_{k} + r \\qquad r \\sim \\mathcal{N}(0, R)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to derive the $EM$ algorithm for the random walk we should write down the complete data log-likelihood for the model given a set of parameters $\\mathbf{\\theta}$ which is:\n",
    "\n",
    "$$\n",
    " \\log p(\\mathbf{y}_{1:T}, \\mathbf{x}_{0:T} | \\theta) = \\log(x_0|\\theta) + \\sum_{k=1}^T \\log p(x_k|x_{k-1}, \\theta) + \\sum_{k=1}^T \\log p(y_k | x_k,\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the $E$ step we define the function $Q(\\theta, \\theta^{(n)})$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Q(\\theta, \\theta^{(n)})& = E[\\log p(\\mathbf{y}_{1:k}, \\mathbf{x}_{0:k} | \\theta)] \\\\\n",
    "                       & = E[\\log(x_0|\\theta)] + \\sum_{k=1}^T E[ \\log p(x_k|x_{k-1}, \\theta) ] + \\sum_{k=1}^T E[\\log p(y_k | x_k,\\theta)]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the expectation $E[.]$ is defined in terms of $p(\\mathbf{x}_{0:T} | \\theta^{(n)}, \\mathbf{y}_{1:T})$. Formally,\n",
    "\n",
    "$$\n",
    "E[g(x)] = \\int g(\\mathbf{x}_{0:T}) p(\\mathbf{x}_{0:T} | \\theta^{(n)}, \\mathbf{y}_{1:T}) d\\mathbf{x}_{0:T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in this case the parameter we want to estimate is the measurement noise variance ($R$) and it only affects $ p(y_k | x_k)$. Then the function $Q(.,.)$ can be rewritten as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Q(R, R^{(n)})& =  \\sum_{k=1}^T E[\\log p(y_k | x_k, R)] + constant \\\\\n",
    "                       & = \\sum_{k=1}^T \\int \\log p(y_k | x_k, R) p(x_k | R^{(n)}, \\mathbf{y}_{1:T}) d{x}_{k} + constant\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to derive the $M$ step. In this step we have to optimize $Q(.,.)$ with respect to $R$. Expanding the last expression we get:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "Q(R, R^{(n)}) & = \\sum_{k=1}^T \\int \\bigg(-\\frac{1}{2}\\log 2\\pi - \\frac{1}{2}\\log R - \\frac{(y_k - x_k)^2}{2R}\\bigg) \\mathcal{N}(x_k | m_k^s, P_k^s) d{x}_{k} + constant \\\\\n",
    "              & = \\sum_{k=1}^T \\int \\bigg(-\\frac{1}{2}\\log 2\\pi - \\frac{1}{2}\\log R - \\frac{(y_k - x_k)^2}{2R}\\bigg) \\mathcal{N}(x_k | m_k^s, P_k^s) d{x}_{k} + constant \\\\\n",
    "              & = \\sum_{k=1}^T -E[\\frac{1}{2}\\log 2\\pi] - E[\\frac{1}{2}\\log R] - \\frac{E[y_k^2]}{2R} + \\frac{E[y_k x_k]}{2R} - \\frac{E[x_k^2]}{2R} + constant\\\\\n",
    "              & = \\sum_{k=1}^T - \\frac{1}{2}\\log R - \\frac{y_k^2}{2R} +  \\frac{2 y_k E[x_k]}{2R} - \\frac{E[x_k^2]}{2R} + constant \\\\\n",
    "              & = \\sum_{k=1}^T - \\frac{1}{2}\\log R - \\frac{y_k^2}{2R} +  \\frac{y_k m_k^s}{R} - \\frac{P_k^s + (m_k^s)^2 }{2R} + constant \\\\\n",
    "              & = \\sum_{k=1}^T - \\frac{1}{2}\\log R - \\frac{y_k^2}{2R} +  \\frac{y_k m_k^s}{R} - \\frac{P_k^s}{2R} - \\frac{(m_k^s)^2 }{2R} + constant\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the the expectation above $E[.]$ is defined in terms of the probability distribution $\\mathcal{N}(x_k | m_k^s, P_k^s)$ where $m_k^s$ and $P_k^s$ are the resulting mean and covariance from the $RTS$ smoother for state $x_k\n",
    "$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to maximize $Q(R, R^{(n)})$ with respect to $R$. Taking derivatives we have.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial Q(R, R^{(n)})}{\\partial R} & = \\frac{\\partial }{\\partial R} \\bigg( \\sum_{k=1}^T - \\frac{1}{2}\\log R - \\frac{y_k^2}{2R} +  \\frac{y_k m_k^s}{R} - \\frac{P_k^s}{2R} - \\frac{(m_k^s)^2 }{2R} \\bigg) \\\\\n",
    "                                          & = \\sum_{k=1}^T - \\frac{1}{2R} + \\frac{y_k^2}{2 R^2} -  \\frac{y_k m_k^s}{R^2} + \\frac{P_k^s}{2R^2} + \\frac{(m_k^s)^2 }{2R^2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to make the derivative equal to $0$ in order to maximize:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{k=1}^T - \\frac{1}{2R} + \\frac{y_k^2}{2 R^2} -  \\frac{y_k m_k^s}{R^2} + \\frac{P_k^s}{2R^2} + \\frac{(m_k^s)^2 }{2R^2}\n",
    "& = 0 \\\\\n",
    "\\sum_{k=1}^T - \\frac{R}{2} + \\frac{y_k^2}{2} - {y_k m_k^s} + \\frac{P_k^s}{2} + \\frac{(m_k^s)^2 }{2}\n",
    "& = 0 \\\\\n",
    " -\\frac{RT}{2} + \\sum_{k=1}^T  \\frac{y_k^2}{2} - {y_k m_k^s} + \\frac{P_k^s}{2} + \\frac{(m_k^s)^2 }{2}\n",
    "& = 0 \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last equality defines an update equation for $R$ using the output (i.e $m_k^s$, $P_k^s$) of the *RTS* smoother using the old value of $R$ (i.e. $R^{(n)}$). Namely,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "R = \\frac{1}{T} \\sum_{k=1}^T  {y_k^2} - 2{y_k m_k^s} + {P_k^s} + {(m_k^s)^2 }\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to iteratively estimate the value of $R$. The implementation is based on the EFK/UKF toolbox since the Kalman filtering and RTS smoothing were already implemented in previous rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script octave\n",
    "   \n",
    "%% Data Generation\n",
    "\n",
    "A = 1;\n",
    "H = 1;\n",
    "steps = 256;\n",
    "T = 1:steps;\n",
    "x = randn;\n",
    "\n",
    "Q = 0.1;\n",
    "R = 3.0;\n",
    "\n",
    "X = zeros(1, steps);\n",
    "Y = zeros(1, steps);\n",
    "for i = 1:steps\n",
    "    x = A * x + sqrt(Q) * randn;\n",
    "    y = H * x + sqrt(R) *randn;\n",
    "    X(i) = x;\n",
    "    Y(i) = y;\n",
    "end\n",
    "\n",
    "\n",
    "%% EM\n",
    "\n",
    "\n",
    "em_iteraciones = 100;\n",
    "\n",
    "R_est = 100; % initial estimation\n",
    "\n",
    "est = zeros(1, em_iteraciones);\n",
    "\n",
    "for i = 1:em_iteraciones\n",
    "\n",
    "    % Kalman Filtering with current parameter value\n",
    "    m0 = 0.0;\n",
    "    P0 = 1;\n",
    "    m = m0;\n",
    "    P = P0;\n",
    "    MM = zeros(size(m,1),size(Y,2));\n",
    "    PP = zeros(size(m,1),size(m,1),size(Y,2));\n",
    "    for k=1:size(Y,2)\n",
    "        [m,P] = kf_predict(m,P,A,Q);\n",
    "        [m,P] = kf_update(m,P,Y(:,k),H,R_est); % using the current estimate\n",
    "        MM(:,k) = m;\n",
    "        PP(:,:,k) = P;\n",
    "    end\n",
    "    % RTS Smoothing \n",
    "    [SM,SP] = rts_smooth(MM,PP,A,Q);\n",
    "    % Actual EM\n",
    "    new_R_est = sum(Y .* Y) - 2 * sum(Y .* SM) + sum(SP) + sum(SM .* SM);\n",
    "    new_R_est = new_R_est / size(Y, 2);\n",
    "    R_est = new_R_est;\n",
    "    est(i) = R_est;\n",
    "end\n",
    "\n",
    "time = 1:em_iteraciones;\n",
    "plot(time , est, time, R );\n",
    "legend('EM Estimation','Real Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAGACAIAAABUQk3oAAAACXBIWXMAAA3XAAAN1wFCKJt4AAAA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\nAABCCQBAKAEACCUAAKH+B5+/bbiHWwhRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='em_convergence_8_1.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Value | EM Estimate | Error\n",
    "--- | --- | ---\n",
    "3.0 | 2.9806 | 0.0194"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
