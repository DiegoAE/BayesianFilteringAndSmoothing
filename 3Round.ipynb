{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Course: Bayesian Filtering and Smoothing.\n",
    "* ### Exercised round: 3\n",
    "* ### Student's name: Diego Alejandro Agudelo Espa√±a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 (Kalman Filter with Non-Zero Mean Noises)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive the Kalman filter equations for the following linear-Gaussian filtering model with non-zero-mean noises:\n",
    "\\begin{align}\n",
    "\t\\mathbf{x}_k &= \\mathbf{A} \\mathbf{x}_{k-1} + \\mathbf{q}_{k-1},\\\\\n",
    "\t\\mathbf{y}_k &= \\mathbf{H} \\mathbf{x}_k + \\mathbf{r}_k,\n",
    "\\end{align}\n",
    "where $\\mathbf{q}_{k-1} \\sim \\mathcal{N}(\\mathbf{m}_q, \\mathbf{Q})$ and $\\mathbf{r}_k \\sim \\mathcal{N}(\\mathbf{m}_r,\\mathbf{R})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercise 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define probabilistically the dynamics and measurement model as follows:\n",
    "\n",
    "$$ p(\\mathbf{x}_k | \\mathbf{x}_{k-1}) = \\mathcal{N}(\\mathbf{x}_k | \\mathbf{A} \\mathbf{x}_{k-1} + \\mathbf{m}_q, \\mathbf{Q})$$\n",
    "\n",
    "$$ p(\\mathbf{y}_k | \\mathbf{x}_{k}) = \\mathcal{N}(\\mathbf{y}_k | \\mathbf{H} \\mathbf{x}_{k} + \\mathbf{m}_r, \\mathbf{R})$$\n",
    "\n",
    "We can also assume that the posterior filtering distribution of the previous time step is given by:\n",
    "\n",
    "$$ p(\\mathbf{x}_{k-1} | \\mathbf{y}_{1:k-1}) =  \\mathcal{N}( \\mathbf{x}_{k-1} | \\mathbf{m}_{k-1}, \\mathbf{P}_{k-1}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start deriving the Kalman filter equations with the prediction step and the *Chapman-Kolmogorov* equation.\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "p(\\mathbf{x}_{k} | \\mathbf{y}_{1:k - 1}) & = \\int p(\\mathbf{x}_k | \\mathbf{x}_{k-1}) p(\\mathbf{x}_{k-1} | \\mathbf{y}_{1:k-1}) d\\mathbf{x}_{k-1} \\\\\n",
    "& = \\int \\mathcal{N}(\\mathbf{x}_k | \\mathbf{A} \\mathbf{x}_{k-1} + \\mathbf{m}_q, \\mathbf{Q}) \\mathcal{N}( \\mathbf{x}_{k-1} | \\mathbf{m}_{k-1}, \\mathbf{P}_{k-1}) d\\mathbf{x}_{k-1} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to continue with the derivation is useful to recall the following property for marginal and conditional Gaussians distributions. Let $x$ and $y$ have the following Gaussian distributions:\n",
    "\n",
    "$$ p(\\mathbf{x}) =  \\mathcal{N}(\\mathbf{x} | \\mathbf{m}, \\mathbf{P})$$\n",
    "\n",
    "$$ p(\\mathbf{y} | \\mathbf{x}) =  \\mathcal{N}(\\mathbf{y} | A \\mathbf{x} + b, \\mathbf{Q})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it holds that the marginal distribution $p(y)$ is algo Gaussian distributed. Especifically,\n",
    "\n",
    "$$ p(\\mathbf{y}) =  \\mathcal{N}(\\mathbf{y} | A \\mathbf{m} + b, \\mathbf{Q} + \\mathbf{A} \\mathbf{P} \\mathbf{A}^\\top) $$\n",
    "\n",
    "Moreover the joint distribution of $\\mathbf{x}$ and $\\mathbf{y}$ is given by:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\mathbf{x} \\\\\n",
    "\\mathbf{y} \\\\\n",
    "\\end{pmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\n",
    "\\bigg(\n",
    "\\begin{pmatrix}\n",
    "\\mathbf{m} \\\\\n",
    "A \\mathbf{m} + b \\\\\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "\\mathbf{P} &  \\mathbf{P} \\mathbf{A}^\\top \\\\\n",
    " \\mathbf{A} \\mathbf{P}^\\top & \\mathbf{Q} + \\mathbf{A} \\mathbf{P} \\mathbf{A}^\\top \\\\\n",
    "\\end{pmatrix}\n",
    "\\bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the marginal property over the derivation of $p(\\mathbf{x}_{k} | \\mathbf{y}_{1:k - 1})$ we get:\n",
    "\n",
    "$$ p(\\mathbf{x}_{k} | \\mathbf{y}_{1:k - 1}) = \\mathcal{N}( \\mathbf{x}_k |\\mathbf{m}_k^{-}, \\mathbf{P}_k^{-})$$\n",
    "\n",
    "with\n",
    "\n",
    "$$ \n",
    "\\mathbf{m}_k^{-} = A \\mathbf{m}_{k-1} + \\mathbf{m}_{q}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{P}_k^{-} = \\mathbf{Q} + \\mathbf{A} \\mathbf{P}_{k-1} \\mathbf{A}^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the derivation of the prediction step. The update step is also necessary to get the Kalman filter equations and it requires to derive the joint distribution between $\\mathbf{x}_k$ and $\\mathbf{y}_k$. By means of the aforementioned property of Gaussians distributed random variables we can similarly derive this joint distribution.\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "p(\\mathbf{x}_{k}, \\mathbf{y}_{k} | \\mathbf{y}_{1:k - 1}) & = p(\\mathbf{y}_k | \\mathbf{x}_{k}) p(\\mathbf{x}_{k} | \\mathbf{y}_{1:k-1}) \\\\\n",
    "& = \\mathcal{N}(\\mathbf{y}_k | \\mathbf{H} \\mathbf{x}_{k} + \\mathbf{m}_r, \\mathbf{R})  \\mathcal{N}( \\mathbf{x}_k |\\mathbf{m}_k^{-}, \\mathbf{P}_k^{-})\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore this joint distribution can be expressed as follows:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\mathbf{x}_k \\\\\n",
    "\\mathbf{y}_k \\\\\n",
    "\\end{pmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\n",
    "\\bigg(\n",
    "\\begin{pmatrix}\n",
    "\\mathbf{m}_k^{-} \\\\\n",
    "\\mathbf{H} \\mathbf{m}_k^{-} + \\mathbf{m}_r \\\\\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "\\mathbf{P}_k^{-} &  \\mathbf{P}_{k}^{-} \\mathbf{H}^\\top \\\\\n",
    "  \\mathbf{H} \\mathbf{P}_{k}^{-}  & \\mathbf{R} + \\mathbf{H} \\mathbf{P}_{k}^{-} \\mathbf{H}^\\top \\\\\n",
    "\\end{pmatrix}\n",
    "\\bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the joint distribution is derived we can condition on $\\mathbf{y}_{k}$ and then find the sought posterior over $\\mathbf{x}_{k}$. This is done by using the properties of conditioned multivariate Gaussians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(\\mathbf{x}_{k} | \\mathbf{y}_{1:k}) = \\mathcal{N}(\\mathbf{x}_{k} | \\mathbf{m}_k, \\mathbf{P}_k)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\mathbf{m}_k = \\mathbf{m}_k^{-} + \\mathbf{P}_{k}^{-} \\mathbf{H}^\\top (\\mathbf{R} + \\mathbf{H} \\mathbf{P}_{k}^{-} \\mathbf{H}^\\top)^{-1} (\\mathbf{y}_k - (\\mathbf{H} \\mathbf{m}_k^{-} + \\mathbf{m}_r))\n",
    "$$\n",
    "$$\n",
    "\\mathbf{P}_k = \\mathbf{P}_k^{-} - \\mathbf{P}_{k}^{-} \\mathbf{H}^\\top (\\mathbf{R} + \\mathbf{H} \\mathbf{P}_{k}^{-} \\mathbf{H}^\\top)^{-1}  \\mathbf{H} \\mathbf{P}_{k}^{-}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or equivalently in the Kalman filter traditional notation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbf{S}_k & = \\mathbf{H} \\mathbf{P}_{k}^{-} \\mathbf{H}^\\top + \\mathbf{R} \\\\\n",
    "    \\mathbf{K}_k & = \\mathbf{P}_{k}^{-} \\mathbf{H}^\\top \\mathbf{S}_k^{-1}\\\\\n",
    "    \\mathbf{m}_k & = \\mathbf{m}_k^{-} + \\mathbf{K}_k (\\mathbf{y}_k - (\\mathbf{H} \\mathbf{m}_k^{-} + \\mathbf{m}_r)) \\\\\n",
    "    \\mathbf{P}_k & = \\mathbf{P}_k^{-} - \\mathbf{K}_{k} \\mathbf{S}_k \\mathbf{K}_{k}^\\top\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3. (Kalman Filter for Noisy Resonator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\t\\mathbf{x} &= \\begin{bmatrix} \\cos(\\omega) & \\frac{\\sin(\\omega)}{\\omega} \\\\ -\\omega \\sin(\\omega) & \\cos(\\omega) \\end{bmatrix} \\mathbf{x}_{k-1} + \\mathbf{q}_{k-1}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_k = \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\mathbf{x}_k + r_k\n",
    "$$\n",
    "\n",
    "where $\\mathbf{x}_k \\in \\mathbb{R}^2$ is the state, $y_k$ is the measurement, $r_k \\sim \\mathcal{N}(0, 0.1)$ is a white Gaussian measurement noise, and $\\mathbf{q}_k \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q})$, where\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\t\\mathbf{Q} = \\begin{bmatrix} \\frac{q^c \\omega - q^c \\cos(\\omega) \\sin(\\omega)}{2 \\omega^3} & \\frac{q^c \\sin^2(\\omega) }{2 \\omega^2} \\\\ \\frac{q^c \\sin^2(\\omega) }{2 \\omega^2} & \\frac{q^c \\omega + q^c \\cos(\\omega) \\sin(\\omega)}{2 \\omega} \\end{bmatrix}.\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "The angular velocity is $\\omega = 1/2$ and the spectral density is $q^c = 0.01$. The model is a discretized version of noisy resonator model with a given angular velocity $\\omega$.\n",
    "\n",
    "In the file ```kf_ex.m``` (in Noppa) there is a simulation of the dynamic model together with a baseline solution, where the measurement is directly used as the estimate of the state component $x_1$ and the second component $x_2$ is computed as a weighted average of the measurement differences.\n",
    "\n",
    "1. Implement the Kalman filter for the model and compare its performance (in RMSE sense) to the baseline solution. Plot figures of the solutions.\n",
    "2. Compute (numerically) the stationary Kalman filter corresponding to the model. Test this stationary filter against the baseline and Kalman filter solutions. Plot the results and report the RMSE values for the solutions. What is the practical difference in the stationary and non-stationary Kalman filter solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercise 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNU Octave, version 3.8.2\n",
      "Copyright (C) 2014 John W. Eaton and others.\n",
      "This is free software; see the source code for copying conditions.\n",
      "There is ABSOLUTELY NO WARRANTY; not even for MERCHANTABILITY or\n",
      "FITNESS FOR A PARTICULAR PURPOSE.  For details, type 'warranty'.\n",
      "\n",
      "Octave was configured for \"x86_64-pc-linux-gnu\".\n",
      "\n",
      "Additional information about Octave is available at http://www.octave.org.\n",
      "\n",
      "Please contribute if you find this software useful.\n",
      "For more information, visit http://www.octave.org/get-involved.html\n",
      "\n",
      "Read http://www.octave.org/bugs.html to learn how to submit bug reports.\n",
      "For information about changes from previous versions, type 'news'.\n",
      "\n",
      "This is the simulated data. Press enter.\n",
      "err1 =  23.527\n",
      "This is the base line estimate. Press enter.\n",
      "err2 =  6.2974\n",
      "This will be the KF estimate. Press enter.\n",
      "err3 =  7.6433\n",
      "This will be the SKF estimate. Press enter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: print.m: epstool binary is not available.\n",
      "Some output formats are not available.\n"
     ]
    }
   ],
   "source": [
    "%%script octave\n",
    "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "%\n",
    "% Becs-114.4610 - Special Course in Bayesian Modelling L:\n",
    "% Bayesian Estimation of Time-Varying Processes (5 cr)\n",
    "%\n",
    "% This software is distributed under the GNU General Public \n",
    "% Licence (version 2 or later); please refer to the file \n",
    "% Licence.txt, included with the software, for details.\n",
    "%\n",
    "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "%% Generate data\n",
    "\n",
    "  % Lock random seed\n",
    "  randn('state',12);\n",
    "  \n",
    "  % rmse function\n",
    "  rmse = @(AA,BB) sum(sum((AA - BB) .* (AA - BB)));\n",
    "\n",
    "  % Substitute Simo's 'gauss_rnd', where m is the mean and S the covariance\n",
    "  gauss_rnd = @(m,S) m + chol(S)' * randn(size(m));\n",
    "  \n",
    "  % Define parameters\n",
    "  steps = 100;  % Number of time steps\n",
    "  w     = 0.5;  % Angular velocity\n",
    "  q     = 0.01; % Process noise spectral density\n",
    "  r     = 0.1;  % Measurement noise variance\n",
    "\n",
    "  % This is the transition matrix\n",
    "  A = [cos(w)    sin(w)/w; \n",
    "       -w*sin(w) cos(w)];\n",
    "\n",
    "  % This is the process noise covariance\n",
    "  Q = [0.5*q*(w-cos(w)*sin(w))/w^3 0.5*q*sin(w)^2/w^2;\n",
    "       0.5*q*sin(w)^2/w^2          0.5*q*(w+cos(w)*sin(w))/w];\n",
    "\n",
    "  % This is the true initial value\n",
    "  x0 = [0;0.1]; \n",
    "\n",
    "  % Simulate data\n",
    "  X = zeros(2,steps);  % The true signal\n",
    "  Y = zeros(1,steps);  % Measurements\n",
    "  T = 1:steps;         % Time\n",
    "  x = x0;\n",
    "  for k=1:steps\n",
    "    x = gauss_rnd(A*x,Q);\n",
    "    y = gauss_rnd(x(1),r);\n",
    "    X(:,k) = x;\n",
    "    Y(:,k) = y;\n",
    "  end\n",
    "\n",
    "  % Visualize\n",
    "  figure; clf;\n",
    "    plot(T,X(1,:),'--',T,Y,'o');\n",
    "    legend('True signal','Measurements');\n",
    "    xlabel('Time step'); title('\\bf Simulated data')\n",
    "  saveas(gcf,'R2_SimulationData.png')\n",
    "    \n",
    "  % Report and pause\n",
    "  fprintf('This is the simulated data. Press enter.\\n');\n",
    "  pause;\n",
    "\n",
    "  \n",
    "%% Baseline solution\n",
    "\n",
    "  % Baseline solution. The estimates\n",
    "  % of x_k are stored as columns of\n",
    "  % the matrix EST1.\n",
    "  \n",
    "  % Calculate baseline estimate\n",
    "  m1 = [0;1];  % Initialize first step with a guess\n",
    "  EST1 = zeros(2,steps);\n",
    "  for k=1:steps\n",
    "    m1(2) = Y(k)-m1(1);\n",
    "    m1(1) = Y(k);\n",
    "    EST1(:,k) = m1;\n",
    "  end\n",
    "\n",
    "  % Visualize results\n",
    "  figure; clf;\n",
    "  \n",
    "  % Plot the signal and its estimate\n",
    "  subplot(2,1,1);\n",
    "    plot(T,X(1,:),'--',T,EST1(1,:),'-',T,Y,'o');\n",
    "    legend('True signal','Estimated signal','Measurements');\n",
    "    xlabel('Time step'); title('\\bf Baseline solution')\n",
    "  \n",
    "  % Plot the derivative and its estimate\n",
    "  subplot(2,1,2);\n",
    "    plot(T,X(2,:),'--',T,EST1(2,:),'-');\n",
    "    legend('True derivative','Estimated derivative');\n",
    "    xlabel('Time step')\n",
    "  saveas(gcf,'R2_BaseLine.png')\n",
    "    \n",
    "  % Compute error\n",
    "  err1 = rmse(X,EST1)\n",
    "  \n",
    "  % Report and pause\n",
    "  fprintf('This is the base line estimate. Press enter.\\n');\n",
    "  pause\n",
    "  \n",
    "  \n",
    "%% Kalman filter\n",
    "  \n",
    "  % Kalman filter solution. The estimates\n",
    "  % of x_k are stored as columns of\n",
    "  % the matrix EST2.\n",
    "\n",
    "  m2 = [0;1];  % Initialize first step\n",
    "  P2 = eye(2); % Some uncertanty in covariance  \n",
    "  EST2 = zeros(2,steps); % Allocate space for results\n",
    "  H = [1, 0];\n",
    "\n",
    "  % Run Kalman filter\n",
    "  for k=1:steps\n",
    "    % Prediction step\n",
    "    m2 = A * m2;\n",
    "    P2 = A * P2 * A' + Q;\n",
    "    % Update step\n",
    "    vk = Y(k) - H * m2;\n",
    "    Sk = H * P2 * H' + r;\n",
    "    Kk = (P2 * H') / Sk;\n",
    "    m2 = m2 + Kk * vk;\n",
    "    P2 = P2 - Kk * Sk * Kk';\n",
    "    % Store the results\n",
    "    % disp(Kk);\n",
    "    EST2(:,k) = m2;\n",
    "  end\n",
    "\n",
    "  % Visualize results\n",
    "  figure; clf\n",
    "  \n",
    "  % Plot the signal and its estimate\n",
    "  subplot(2,1,1);\n",
    "    plot(T,X(1,:),'--',T,EST2(1,:),'-',T,Y,'o');\n",
    "    legend('True signal','Estimated signal','Measurements');\n",
    "    xlabel('Time step'); title('\\bf Kalman filter')\n",
    "  \n",
    "  % Plot the derivative and its estimate\n",
    "  subplot(2,1,2);\n",
    "    plot(T,X(2,:),'--',T,EST2(2,:),'-');\n",
    "    legend('True derivative','Estimated derivative');\n",
    "    xlabel('Time step')\n",
    "  saveas(gcf,'R2_KalmanFilter.png')\n",
    "\n",
    "  % Compute error\n",
    "  err2 = rmse(X,EST2)\n",
    "\n",
    "  % Report and pause\n",
    "  fprintf('This will be the KF estimate. Press enter.\\n');\n",
    "  pause;\n",
    "\n",
    "\n",
    "%% Stationary Kalman filter solution\n",
    "\n",
    "  % The estimates of x_k are stored as columns of\n",
    "  % the matrix EST3.\n",
    "\n",
    "  m3 = [0;1];  % Initialize first step\n",
    "  P3 = eye(2); % Some uncertanty in covariance  \n",
    "  K  = [0.42498; 0.11114];  % Store the stationary gain here \n",
    "  \n",
    "  EST3 = zeros(2,steps); % Allocate space for results\n",
    "\n",
    "  for k=1:steps\n",
    "    % Replace these with the stationary Kalman filter equations\n",
    "    m3 = (A - K * H * A) * m3  + K * Y(k);\n",
    "    \n",
    "    % Store the results\n",
    "    EST3(:,k) = m3;\n",
    "  end\n",
    "\n",
    "  % Visualize results\n",
    "  figure; clf\n",
    "  \n",
    "  % Plot the signal and its estimate\n",
    "  subplot(2,1,1);\n",
    "    plot(T,X(1,:),'--',T,EST3(1,:),'-',T,Y,'o');\n",
    "    legend('True signal','Estimated signal','Measurements');\n",
    "    xlabel('Time step'); ; title('\\bf Stationary Kalman filter')\n",
    "  \n",
    "  % Plot the derivative and its estimate\n",
    "  subplot(2,1,2);\n",
    "    plot(T,X(2,:),'--',T,EST3(2,:),'-');\n",
    "    legend('True derivative','Estimated derivative');\n",
    "    xlabel('Time step')\n",
    "  saveas(gcf,'R2_StationaryKalmanFilter.png')\n",
    " \n",
    "  % Compute error\n",
    "  err3 = rmse(X,EST3)\n",
    "\n",
    "  % Report and pause\n",
    "  fprintf('This will be the SKF estimate. Press enter.\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"R2_SimulationData.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"R2_BaseLine.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"R2_KalmanFilter.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"R2_StationaryKalmanFilter.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stationary Kalman gain numerically computed was:\n",
    "\n",
    "$$\n",
    "K =\n",
    "\\begin{bmatrix}\n",
    "    0.42498 \\\\\n",
    "    0.11114\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE for the stationary Kalman Filter was $7.6433$ which is much better than the baseline solution RMSE ($23.527$) and slightly higher than the Kalman filter RMSE ($6.2974$).\n",
    "\n",
    "Comparing the Kalman filter and it stationary version it can be stated that there is not practical difference once the Kalman gain matrix has reached the stationary state (i.e. it becomes constant). The subtle performance differences between the stationary and non-stationary version occur while the Kalman is getting close the stationary state. For this particular exercise example it does not take so long for the Kalman gain to become stationary, that is why the performance difference is small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
